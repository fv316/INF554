{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Packages \n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Progressbar\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from tqdm import tqdm # progess bar\n",
    "import pickle\n",
    "\n",
    "# For graphs\n",
    "import networkx as nx \n",
    "import stellargraph as sg\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from stellargraph.layer import GraphSAGE, HinSAGE, link_classification\n",
    "from stellargraph import globalvar\n",
    "\n",
    "from stellargraph.layer import MeanAggregator\n",
    "\n",
    "# For DL\n",
    "from tensorflow import keras \n",
    "######\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=2, allow_soft_placement=True, device_count = {'CPU': 8})\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"30\"\n",
    "\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For processing node texts\n",
    "#import spacy\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text as fe\n",
    "\n",
    "# Dimensionality reduction\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "# Word embeddings\n",
    "#import gensim \n",
    "#from gensim.models import Word2Vec\n",
    "\n",
    "# For stemming\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.feature_extraction import text as fe\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import keras\n",
    "import lightgbm\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33226 500\n"
     ]
    }
   ],
   "source": [
    "path = r\"pickles/word_matrix300id.PICKLE\"\n",
    "with open(path, 'rb') as f:\n",
    "    word_matrix = pickle.load(f)\n",
    "    word_matrix = np.asarray(word_matrix)\n",
    "f.close()\n",
    "\n",
    "# Storing in dataframe\n",
    "n1, n2 = word_matrix.shape\n",
    "# Creating feature names\n",
    "feature_names = [\"w_{}\".format(ii) for ii in range(n2)]\n",
    "ids = sorted(range(n1), key=str)\n",
    "node_data = pd.DataFrame(data=word_matrix, index=ids, columns=feature_names)\n",
    "print(n1,n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples shape: (453797, 3)\n",
      "Testing examples shape: (113450, 2)\n"
     ]
    }
   ],
   "source": [
    "with open(r\"training.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    training  = list(reader)\n",
    "# in order of training examples\n",
    "training = [element[0].split(\" \") for element in training]\n",
    "training = pd.DataFrame(training, columns=['Node1', 'Node2', 'Link'])\n",
    "print(\"Training examples shape: {}\".format(training.shape))\n",
    "\n",
    "with open(r\"testing.txt\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    testing  = list(reader)\n",
    "# in order of testing examples\n",
    "testing = [element[0].split(\" \") for element in testing]\n",
    "testing = pd.DataFrame(testing, columns=['Node1', 'Node2'])\n",
    "print(\"Testing examples shape: {}\".format(testing.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_path = r\"pickles/perf_val_data_final.PICKLE\"\n",
    "if os.path.exists(feature_vector_path):\n",
    "    with open(feature_vector_path, 'rb') as f:\n",
    "        perf_val_data = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "feature_vector_path = r\"pickles/perf_test_data_final.PICKLE\"\n",
    "if os.path.exists(feature_vector_path):\n",
    "    with open(feature_vector_path, 'rb') as f:\n",
    "        perf_test_data = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22689/22689 [00:23<00:00, 983.12it/s] \n",
      "100%|██████████| 113450/113450 [01:54<00:00, 987.29it/s] \n"
     ]
    }
   ],
   "source": [
    "def average(index, dataset):\n",
    "    node1 = dataset['Node1'][index]\n",
    "    node2 = dataset['Node2'][index]\n",
    "    index1 = ids.index(int(node1))\n",
    "    index2 = ids.index(int(node2))\n",
    "    \n",
    "    sim = (node_data.loc[index1]+node_data.loc[index2])/2 # Change binary operator to whatever here ....\n",
    "    return sim.to_numpy()\n",
    "\n",
    "feature_names = [\"doc2vec_average{}\".format(ii) for ii in range(500)]\n",
    "\n",
    "perf_val_data['doc2vec_average']=list(map(lambda i:average(i, training), \n",
    "                                              tqdm(perf_val_data['original_index'], position=0, leave=True)))\n",
    "perf_test_data['doc2vec_average']=list(map(lambda i:average(i, testing), \n",
    "                                               tqdm(perf_test_data['original_index'], position=0, leave=True)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(feature_vector_path, '+wb') as f:\n",
    "    pickle.dump(perf_val_data, f)\n",
    "f.close()\n",
    "\n",
    "with open(feature_vector_path, '+wb') as f:\n",
    "    pickle.dump(perf_test_data, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc2vec_average0</th>\n",
       "      <th>doc2vec_average1</th>\n",
       "      <th>doc2vec_average2</th>\n",
       "      <th>doc2vec_average3</th>\n",
       "      <th>doc2vec_average4</th>\n",
       "      <th>doc2vec_average5</th>\n",
       "      <th>doc2vec_average6</th>\n",
       "      <th>doc2vec_average7</th>\n",
       "      <th>doc2vec_average8</th>\n",
       "      <th>doc2vec_average9</th>\n",
       "      <th>...</th>\n",
       "      <th>doc2vec_average490</th>\n",
       "      <th>doc2vec_average491</th>\n",
       "      <th>doc2vec_average492</th>\n",
       "      <th>doc2vec_average493</th>\n",
       "      <th>doc2vec_average494</th>\n",
       "      <th>doc2vec_average495</th>\n",
       "      <th>doc2vec_average496</th>\n",
       "      <th>doc2vec_average497</th>\n",
       "      <th>doc2vec_average498</th>\n",
       "      <th>doc2vec_average499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21155</th>\n",
       "      <td>-0.020063</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>-0.058800</td>\n",
       "      <td>0.260004</td>\n",
       "      <td>0.823371</td>\n",
       "      <td>0.124695</td>\n",
       "      <td>-0.051623</td>\n",
       "      <td>-0.095660</td>\n",
       "      <td>-0.171536</td>\n",
       "      <td>0.119674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>0.071236</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.124876</td>\n",
       "      <td>-0.031379</td>\n",
       "      <td>0.249358</td>\n",
       "      <td>-0.013508</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.007654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>0.394569</td>\n",
       "      <td>-0.389487</td>\n",
       "      <td>-0.055986</td>\n",
       "      <td>-0.213530</td>\n",
       "      <td>-0.097315</td>\n",
       "      <td>-0.491774</td>\n",
       "      <td>0.542253</td>\n",
       "      <td>0.563140</td>\n",
       "      <td>1.171107</td>\n",
       "      <td>0.003436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418845</td>\n",
       "      <td>0.298539</td>\n",
       "      <td>-0.031765</td>\n",
       "      <td>-0.624266</td>\n",
       "      <td>0.024696</td>\n",
       "      <td>0.103616</td>\n",
       "      <td>0.077364</td>\n",
       "      <td>-0.793604</td>\n",
       "      <td>0.443700</td>\n",
       "      <td>-0.069849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>0.042739</td>\n",
       "      <td>-0.289233</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>-0.218276</td>\n",
       "      <td>-0.099425</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>-0.050894</td>\n",
       "      <td>0.031364</td>\n",
       "      <td>-0.008077</td>\n",
       "      <td>-0.049247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048522</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>-0.125034</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.034088</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>-0.029699</td>\n",
       "      <td>-0.055352</td>\n",
       "      <td>0.140198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>-0.079235</td>\n",
       "      <td>-0.219151</td>\n",
       "      <td>-0.019431</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>-0.077348</td>\n",
       "      <td>0.041631</td>\n",
       "      <td>0.081416</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>-0.019787</td>\n",
       "      <td>0.060417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>-0.129307</td>\n",
       "      <td>-0.250856</td>\n",
       "      <td>0.016768</td>\n",
       "      <td>-0.016657</td>\n",
       "      <td>0.441415</td>\n",
       "      <td>0.273992</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>0.049225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8588</th>\n",
       "      <td>1.118262</td>\n",
       "      <td>0.385503</td>\n",
       "      <td>-0.742771</td>\n",
       "      <td>0.283396</td>\n",
       "      <td>-0.365477</td>\n",
       "      <td>-0.145103</td>\n",
       "      <td>-0.024366</td>\n",
       "      <td>0.142328</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>-0.010650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100515</td>\n",
       "      <td>0.228956</td>\n",
       "      <td>0.418196</td>\n",
       "      <td>0.209789</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>-0.102237</td>\n",
       "      <td>-0.636528</td>\n",
       "      <td>-0.132150</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>0.037607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.054001</td>\n",
       "      <td>0.021581</td>\n",
       "      <td>0.271279</td>\n",
       "      <td>-0.008193</td>\n",
       "      <td>0.100828</td>\n",
       "      <td>0.067756</td>\n",
       "      <td>-0.026939</td>\n",
       "      <td>-0.035822</td>\n",
       "      <td>0.041048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130872</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>-0.443449</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>-0.005536</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>0.024159</td>\n",
       "      <td>0.086958</td>\n",
       "      <td>-0.018980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20589</th>\n",
       "      <td>0.259838</td>\n",
       "      <td>-0.213578</td>\n",
       "      <td>-0.374419</td>\n",
       "      <td>0.209607</td>\n",
       "      <td>0.459305</td>\n",
       "      <td>0.387589</td>\n",
       "      <td>0.333880</td>\n",
       "      <td>-0.394993</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>-0.439540</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.407241</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>-0.011838</td>\n",
       "      <td>-1.239350</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>-1.020851</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>-0.655348</td>\n",
       "      <td>0.128691</td>\n",
       "      <td>-0.473293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19417</th>\n",
       "      <td>-0.193987</td>\n",
       "      <td>1.043525</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.624679</td>\n",
       "      <td>0.441421</td>\n",
       "      <td>-0.170685</td>\n",
       "      <td>0.159183</td>\n",
       "      <td>0.122273</td>\n",
       "      <td>-0.040909</td>\n",
       "      <td>0.427975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055863</td>\n",
       "      <td>-0.057339</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>0.346912</td>\n",
       "      <td>0.384794</td>\n",
       "      <td>-0.180021</td>\n",
       "      <td>0.085751</td>\n",
       "      <td>-0.043945</td>\n",
       "      <td>0.739188</td>\n",
       "      <td>-0.221828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>-0.006543</td>\n",
       "      <td>0.152056</td>\n",
       "      <td>0.067065</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>0.074682</td>\n",
       "      <td>-0.441345</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069179</td>\n",
       "      <td>-0.044413</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>-0.337567</td>\n",
       "      <td>0.547179</td>\n",
       "      <td>-0.004212</td>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.061947</td>\n",
       "      <td>-0.103081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>0.091787</td>\n",
       "      <td>0.045790</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.136462</td>\n",
       "      <td>0.011551</td>\n",
       "      <td>-0.005372</td>\n",
       "      <td>-0.034014</td>\n",
       "      <td>-0.312643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009911</td>\n",
       "      <td>0.016265</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.036004</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>0.067872</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>-0.026196</td>\n",
       "      <td>0.047945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13613 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc2vec_average0  doc2vec_average1  doc2vec_average2  doc2vec_average3  \\\n",
       "21155         -0.020063          0.052347         -0.058800          0.260004   \n",
       "2879           0.394569         -0.389487         -0.055986         -0.213530   \n",
       "5038           0.042739         -0.289233          0.020959         -0.218276   \n",
       "4736          -0.079235         -0.219151         -0.019431          0.018875   \n",
       "8588           1.118262          0.385503         -0.742771          0.283396   \n",
       "...                 ...               ...               ...               ...   \n",
       "4574           0.037439          0.054001          0.021581          0.271279   \n",
       "20589          0.259838         -0.213578         -0.374419          0.209607   \n",
       "19417         -0.193987          1.043525         -0.000199          0.624679   \n",
       "16049         -0.013320          0.004675         -0.006543          0.152056   \n",
       "2525           0.091787          0.045790          0.036576          0.028463   \n",
       "\n",
       "       doc2vec_average4  doc2vec_average5  doc2vec_average6  doc2vec_average7  \\\n",
       "21155          0.823371          0.124695         -0.051623         -0.095660   \n",
       "2879          -0.097315         -0.491774          0.542253          0.563140   \n",
       "5038          -0.099425          0.010675         -0.050894          0.031364   \n",
       "4736          -0.077348          0.041631          0.081416          0.013799   \n",
       "8588          -0.365477         -0.145103         -0.024366          0.142328   \n",
       "...                 ...               ...               ...               ...   \n",
       "4574          -0.008193          0.100828          0.067756         -0.026939   \n",
       "20589          0.459305          0.387589          0.333880         -0.394993   \n",
       "19417          0.441421         -0.170685          0.159183          0.122273   \n",
       "16049          0.067065          0.001512          0.069608          0.074682   \n",
       "2525           0.005624          0.136462          0.011551         -0.005372   \n",
       "\n",
       "       doc2vec_average8  doc2vec_average9  ...  doc2vec_average490  \\\n",
       "21155         -0.171536          0.119674  ...            0.035858   \n",
       "2879           1.171107          0.003436  ...           -0.418845   \n",
       "5038          -0.008077         -0.049247  ...            0.048522   \n",
       "4736          -0.019787          0.060417  ...            0.015948   \n",
       "8588           0.024896         -0.010650  ...           -0.100515   \n",
       "...                 ...               ...  ...                 ...   \n",
       "4574          -0.035822          0.041048  ...            0.130872   \n",
       "20589          0.020934         -0.439540  ...           -1.407241   \n",
       "19417         -0.040909          0.427975  ...            0.055863   \n",
       "16049         -0.441345          0.001332  ...            0.069179   \n",
       "2525          -0.034014         -0.312643  ...           -0.009911   \n",
       "\n",
       "       doc2vec_average491  doc2vec_average492  doc2vec_average493  \\\n",
       "21155            0.071236           -0.007832           -0.124876   \n",
       "2879             0.298539           -0.031765           -0.624266   \n",
       "5038             0.010676           -0.000310           -0.125034   \n",
       "4736             0.007363           -0.129307           -0.250856   \n",
       "8588             0.228956            0.418196            0.209789   \n",
       "...                   ...                 ...                 ...   \n",
       "4574            -0.002113           -0.443449            0.006641   \n",
       "20589            0.304945           -0.011838           -1.239350   \n",
       "19417           -0.057339           -0.004505            0.346912   \n",
       "16049           -0.044413            0.002426            0.016385   \n",
       "2525             0.016265            0.001355            0.036004   \n",
       "\n",
       "       doc2vec_average494  doc2vec_average495  doc2vec_average496  \\\n",
       "21155           -0.031379            0.249358           -0.013508   \n",
       "2879             0.024696            0.103616            0.077364   \n",
       "5038             0.009019            0.034088            0.004515   \n",
       "4736             0.016768           -0.016657            0.441415   \n",
       "8588             0.011820           -0.102237           -0.636528   \n",
       "...                   ...                 ...                 ...   \n",
       "4574             0.015395           -0.005536           -0.000640   \n",
       "20589            0.038491           -1.020851            0.016780   \n",
       "19417            0.384794           -0.180021            0.085751   \n",
       "16049           -0.337567            0.547179           -0.004212   \n",
       "2525            -0.001184            0.067872            0.022864   \n",
       "\n",
       "       doc2vec_average497  doc2vec_average498  doc2vec_average499  \n",
       "21155            0.014364            0.003491           -0.007654  \n",
       "2879            -0.793604            0.443700           -0.069849  \n",
       "5038            -0.029699           -0.055352            0.140198  \n",
       "4736             0.273992            0.047529            0.049225  \n",
       "8588            -0.132150            0.134350            0.037607  \n",
       "...                   ...                 ...                 ...  \n",
       "4574             0.024159            0.086958           -0.018980  \n",
       "20589           -0.655348            0.128691           -0.473293  \n",
       "19417           -0.043945            0.739188           -0.221828  \n",
       "16049           -0.001307            0.061947           -0.103081  \n",
       "2525             0.026175           -0.026196            0.047945  \n",
       "\n",
       "[13613 rows x 500 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['doc2vec_average']\n",
    "X = pd.DataFrame(perf_val_data[cols].doc2vec_average.tolist(), columns=feature_names)\n",
    "y = perf_val_data['Link']\n",
    "y = list(map(lambda i: int(i), y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7486445456517025\n"
     ]
    }
   ],
   "source": [
    "lgbm = lightgbm.LGBMClassifier(verbose=1)\n",
    "model_lgbm = lgbm.fit(X_train, y_train)\n",
    "predictions = model_lgbm.predict(X_test)\n",
    "print(f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
